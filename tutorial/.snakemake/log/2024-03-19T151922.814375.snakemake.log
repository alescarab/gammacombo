Building DAG of jobs...
Using shell: /cvmfs/lhcbdev.cern.ch/conda/envs/default/2024-03-12_19-29/linux-64/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                count
---------------  -------
all                    1
build_wspc             8
run_plugin             8
run_pluginbatch       40
run_prob               8
total                 65

Select jobs to execute...

[Tue Mar 19 15:19:29 2024]
rule build_wspc:
    output: workspace_PIPIEE_4.root
    log: build_workspace_PIPIEE_4.log
    jobid: 5
    reason: Forced execution
    wildcards: decay=PIPIEE, bin_number=4
    resources: tmpdir=/tmp/ascarabo

[Tue Mar 19 15:19:29 2024]
Error in rule build_wspc:
    jobid: 5
    output: workspace_PIPIEE_4.root
    log: build_workspace_PIPIEE_4.log (check log file(s) for error details)
    shell:
         bin/tutorial_dataset_build_workspace --decay PIPIEE --bin 4 > build_workspace_PIPIEE_4.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-03-19T151922.814375.snakemake.log
