Building DAG of jobs...
Using shell: /cvmfs/lhcbdev.cern.ch/conda/envs/default/2023-03-05_13-05/linux-64/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
all                    1              1              1
run_plugin             1              1              1
run_pluginbatch        5              1              1
run_prob               1              1              1
total                  8              1              1

Select jobs to execute...

[Fri Mar 17 10:24:56 2023]
rule run_prob:
    input: workspace.root
    output: root/scan1dDatasetsProb_PDF_Dataset_50p_branchingRatio.root
    log: tutorial_dataset_prob_PDF_Dataset_50p_branchingRatio.log
    jobid: 2
    reason: Updated input files: workspace.root
    wildcards: name=PDF_Dataset, points=50, var=branchingRatio
    resources: tmpdir=/tmp/ascarabo

Terminating processes on user request, this might take some time.
[Fri Mar 17 10:37:43 2023]
Error in rule run_prob:
    jobid: 2
    output: root/scan1dDatasetsProb_PDF_Dataset_50p_branchingRatio.root
    log: tutorial_dataset_prob_PDF_Dataset_50p_branchingRatio.log (check log file(s) for error message)
    shell:
        export PATH=/usr/local/bin:/usr/bin ;set +u ;source ../scripts/setup_lxplus.sh ; bin/tutorial_dataset --var branchingRatio --npoints 50 --scanrange 0:1.e-6 --cls 2 --CL 90 --CL 95 > tutorial_dataset_prob_PDF_Dataset_50p_branchingRatio.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2023-03-17T102428.816526.snakemake.log
